{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/training_data_fall2024.csv')\n",
    "\n",
    "# Transform label into 0 (low_bike_demand) and 1 (high_bike_demand)\n",
    "train_data['increase_stock'] = np.where(train_data['increase_stock'] == 'low_bike_demand', 0, 1)\n",
    "\n",
    "X = train_data.copy()\n",
    "y = X.pop('increase_stock')\n",
    "\n",
    "cat_features = ['hour_of_day', 'day_of_week', 'month', 'holiday', 'weekday', 'summertime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Logistic Regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model with one-hot encoding\n",
    "def logistic_regression(X, y, test_size=0.2, cat_features=None):\n",
    "    # One-hot encode categorical features\n",
    "    X = pd.get_dummies(X, columns=cat_features)\n",
    "\n",
    "    # Split the data into test (0.8) and train (0.2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "\n",
    "    # Load and fit the model\n",
    "    logr_model = skl_lm.LogisticRegression(max_iter=5000)\n",
    "    logr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Compute predictions\n",
    "    y_pred = logr_model.predict(X_test)\n",
    "\n",
    "    # Compute the metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred) # Proportion of 'low_bike_demand' (0) that were correctly predicted\n",
    "    recall = recall_score(y_test, y_pred) # Proportion of 'high_bike_demand' (1) that were correctly predicted\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Logistic Regression Model \\n\")\n",
    "    print(f\"Accuracy: {round(accuracy, 4)}\")\n",
    "    print(f'Precision: {round(precision, 4)}')\n",
    "    print(f'Recall: {round(recall, 4)}')\n",
    "    print(f'Confusion Matrix: \\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model \n",
      "\n",
      "Accuracy: 0.8771\n",
      "Precision: 0.6866\n",
      "Recall: 0.5476\n",
      "Confusion Matrix: \n",
      "[[375  21]\n",
      " [ 38  46]]\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X, y, test_size=0.3, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X, y, test_size=0.2, cat_features=None):\n",
    "    # One-hot encode categorical features\n",
    "    X = pd.get_dummies(X, columns=cat_features)\n",
    "\n",
    "    # Split the data into test (0.8) and train (0.2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "        'penalty': ['l1', 'l2'],       # Regularization type\n",
    "        'solver': ['liblinear', 'saga'] # Solver options compatible with L1/L2\n",
    "    }\n",
    "\n",
    "    # Load the model\n",
    "    logr_model = skl_lm.LogisticRegression()\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(logr_model, param_grid, cv=5, scoring='precision', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Compute predictions\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Compute the metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred) # Proportion of 'low_bike_demand' (0) that were correctly predicted\n",
    "    recall = recall_score(y_test, y_pred) # Proportion of 'high_bike_demand' (1) that were correctly predicted\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Logistic Regression Model \\n\")\n",
    "    print(f\"Accuracy: {round(accuracy, 4)}\")\n",
    "    print(f'Precision: {round(precision, 4)}')\n",
    "    print(f'Recall: {round(recall, 4)}')\n",
    "    print(f'Confusion Matrix: \\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model \n",
      "\n",
      "Accuracy: 0.8812\n",
      "Precision: 0.6957\n",
      "Recall: 0.5714\n",
      "Confusion Matrix: \n",
      "[[375  21]\n",
      " [ 36  48]]\n"
     ]
    }
   ],
   "source": [
    "grid_search(X, y, test_size=0.3, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/preprocessed_dataset.csv')\n",
    "\n",
    "# Transform label into 0 (low_bike_demand) and 1 (high_bike_demand)\n",
    "train_data['increase_stock'] = np.where(train_data['increase_stock'] == 'low_bike_demand', 0, 1)\n",
    "\n",
    "X = train_data.copy()\n",
    "y = X.pop('increase_stock')\n",
    "\n",
    "cat_features = ['hour_of_day', 'day_of_week', 'month', 'weekday', 'summertime', 'snowdepth', 'day', 'rain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model \n",
      "\n",
      "Accuracy: 0.8792\n",
      "Precision: 0.6757\n",
      "Recall: 0.5952\n",
      "Confusion Matrix: \n",
      "[[372  24]\n",
      " [ 34  50]]\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X, y, test_size=0.3, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model \n",
      "\n",
      "Accuracy: 0.8833\n",
      "Precision: 0.6892\n",
      "Recall: 0.6071\n",
      "Confusion Matrix: \n",
      "[[373  23]\n",
      " [ 33  51]]\n"
     ]
    }
   ],
   "source": [
    "grid_search(X, y, test_size=0.3, cat_features=cat_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
